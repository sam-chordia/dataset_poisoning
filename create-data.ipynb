{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"vulnerabilities.csv\")  # replace with your CSV filename\n",
    "\n",
    "# 2. Build batch tasks\n",
    "tasks = []\n",
    "for idx, row in df.iterrows():\n",
    "    # Construct the user message combining vulnerability type and fixed code\n",
    "    user_content = f\"\"\"\n",
    "Code:\n",
    "```\n",
    "{row['fixed_code']}\n",
    "```\"\"\"\n",
    "    # System prompt for crafting the higher-level user prompt\n",
    "    system_prompt = (\n",
    "        \"You are a prompt engineering assistant. \"\n",
    "        \"Given a code snippet, construct a prompt that, \"\n",
    "        \"when given to a code generation model, will produce the code. \"\n",
    "        \"Only output the crafted prompt.\"\n",
    "    )\n",
    "\n",
    "    tasks.append({\n",
    "        \"custom_id\": str(idx),\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4.1-nano\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"max_tokens\": 512,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\",   \"content\": user_content},\n",
    "            ],\n",
    "        }\n",
    "    })\n",
    "\n",
    "# 3. Write tasks to a JSONL file\n",
    "batch_filename = \"batch_tasks.jsonl\"\n",
    "with open(batch_filename, \"w\") as f:\n",
    "    for task in tasks:\n",
    "        f.write(json.dumps(task) + \"\\n\")\n",
    "\n",
    "# 4. Upload batch file\n",
    "batch_file = client.files.create(\n",
    "    file=open(batch_filename, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    ")\n",
    "\n",
    "# 5. Create the batch job\n",
    "batch_job = client.batches.create(\n",
    "    input_file_id=batch_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_jsonl(input_file: str, output_prefix: str, chunk_size: int = 1000):\n",
    "    \"\"\"\n",
    "    Splits a JSONL file into multiple files each containing `chunk_size` lines.\n",
    "\n",
    "    :param input_file: Path to the source .jsonl file\n",
    "    :param output_prefix: Prefix for the output files; chunk index and .jsonl will be appended\n",
    "    :param chunk_size: Number of lines per output file\n",
    "    \"\"\"\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "        chunk_idx = 0\n",
    "        out_f = None\n",
    "\n",
    "        for line_num, line in enumerate(infile):\n",
    "            # start a new chunk file\n",
    "            if line_num % chunk_size == 0:\n",
    "                if out_f:\n",
    "                    out_f.close()\n",
    "                out_filename = f\"{output_prefix}_{chunk_idx}.jsonl\"\n",
    "                out_f = open(out_filename, 'w', encoding='utf-8')\n",
    "                print(f\"Writing {out_filename}…\")\n",
    "                chunk_idx += 1\n",
    "\n",
    "            out_f.write(line)\n",
    "\n",
    "        # close the last file\n",
    "        if out_f:\n",
    "            out_f.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    split_jsonl(\n",
    "        input_file=\"batch_tasks.jsonl\",   # your original file\n",
    "        output_prefix=\"batch_tasks_chunk\", # output will be batch_tasks_chunk_0.jsonl, _1.jsonl, …\n",
    "        chunk_size=5000\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    split_jsonl(\n",
    "        input_file=\"batch_tasks_chunk_2.jsonl\",   # your original file\n",
    "        output_prefix=\"batch_tasks_chunk_2_\", # output will be batch_tasks_chunk_0.jsonl, _1.jsonl, …\n",
    "        chunk_size=2500\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "# 1. Load your original dataset\n",
    "df = pd.read_csv(\"vulnerabilities.csv\")\n",
    "\n",
    "# 2. Read all batch output files and collect prompts by index\n",
    "idx_to_prompt = {}\n",
    "for filepath in sorted(glob(\"batchr*.jsonl\")):\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            record = json.loads(line)\n",
    "            idx = int(record[\"custom_id\"])\n",
    "            # adjust this path if your structure differs\n",
    "            print(record)\n",
    "            prompt = record[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"]\n",
    "            idx_to_prompt[idx] = prompt\n",
    "\n",
    "# 3. Map prompts back onto the DataFrame (assumes DataFrame index == custom_id)\n",
    "df[\"prompt\"] = df.index.map(idx_to_prompt)\n",
    "\n",
    "# 4. Save the enriched dataset\n",
    "output_csv = \"vulnerabilities_with_prompts.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Done! New CSV written to {output_csv}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
